{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "Day1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jear2412/ComputoCientifico/blob/master/KerasDay1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTpcvzLhlp_g"
      },
      "source": [
        "# **Keras -- Practical Session 1**\n",
        "## **Modelos Epidemiol√≥gicos, 2020**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxAx4Dz4lp_q"
      },
      "source": [
        "#Sesion de Keras impartida por Alan Gerardo Reyes, CIMAT\n",
        "# 12 de noviembre 2020\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from time import time\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras import activations, initializers, optimizers, callbacks\n",
        "from tensorflow.keras.layers import Layer, Input, Dense, Dropout, Activation, Add\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFW9WQexlp_9"
      },
      "source": [
        "## Generating synthetic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz82VQOLlp_-"
      },
      "source": [
        "def f(x, sigma):\n",
        "    eps = sigma * np.random.randn(*x.shape)\n",
        "    y1 = 10. * np.sin(2.*np.pi*x) \n",
        "    y2 = 3.0 * np.sin(3.*np.pi*x)\n",
        "    return y1 + y2 + eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA68I7s2lqAX"
      },
      "source": [
        "def g(x, sigma):\n",
        "    eps = sigma * np.random.randn(*x.shape)\n",
        "    y1 = 1. * np.sin(2.*np.pi*x) / (0.01 + x)\n",
        "    y2 = 3.0 * np.log(1. + x)\n",
        "    return y1 + y2 + eps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePadZxBolqAn"
      },
      "source": [
        "train_size = 500\n",
        "noise = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpGFQ35IlqAv"
      },
      "source": [
        "x = np.linspace(-2., 2., train_size).reshape(-1,1)\n",
        "print(x.shape)\n",
        "\n",
        "y = f(x, sigma=noise)\n",
        "y_true = f(x, sigma=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGilmpvzlqA3"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x, y_true, label='true')\n",
        "plt.plot(x, y, 'k+', label='data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt8zpBPRlqA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQhWX_zplqBE"
      },
      "source": [
        "## Split data in Train / Validaton / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSCJBIPKlqBE"
      },
      "source": [
        "n = x.shape[0]\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3nNAH-lqBJ"
      },
      "source": [
        "# shuffle index\n",
        "seed = np.random.seed(12112020)\n",
        "idx = np.random.permutation(np.arange(0, n))\n",
        "print(idx[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_R0cFEglqBO"
      },
      "source": [
        "# define percentages train / validation / test\n",
        "p_train = 0.7\n",
        "p_val   = 0.15\n",
        "\n",
        "# define index where the data will be cut\n",
        "a = int(n*p_train)\n",
        "b = int(n*(p_train + p_val))\n",
        "\n",
        "# split\n",
        "x_train = x[idx[:a]]\n",
        "x_val   = x[idx[a:b]]\n",
        "x_test  = x[idx[b:]]\n",
        "\n",
        "y_train = y[idx[:a]]\n",
        "y_val   = y[idx[a:b]]\n",
        "y_test  = y[idx[b:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0HN-wRGlqBS"
      },
      "source": [
        "The input and output data for a keras neural network must be in the form of numpy arrays. \n",
        "\n",
        "The input data (x_train, x_val, x_test) must be of shaope $(n,d_1)$, where $n$ is the number of samples, $d_1$ the dimension of each sample.\n",
        "Same for the output data (y_train, y_val, y_test) must be of shaope $(n,d_2)$, where $n$ is the number of samples, $d_2$ the dimension of each output sample.\n",
        "\n",
        "If not, you can use the numpy $\\texttt{reshape}$ attribute to modify the shape of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gxhiu6ylqBS"
      },
      "source": [
        "# print shape of data (just for verification)\n",
        "print(x_train.shape, x_val.shape, x_test.shape)\n",
        "print(y_train.shape, y_val.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ngYLPTOlqBY"
      },
      "source": [
        "# plot x_train and y_train data\n",
        "plt.figure()\n",
        "plt.plot(x_train, y_true[idx[:int(n*p_train)]], 'b.', label='true')\n",
        "plt.plot(x_train, y_train, 'k+', label='data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKRpVUrMlqBe"
      },
      "source": [
        "# define input_shape\n",
        "input_shape = x_train.shape[1:]\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkEaCuXAlqBi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ziXqZxlqBm"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzkim51olqBn"
      },
      "source": [
        "def fully_connected_model(input_shape):\n",
        "    I = Input(input_shape, name='input')                # input layer\n",
        "    X = Dense(8, activation='relu', name='dense1')(I)   # dense layer 1\n",
        "    X = Dense(1, activation=None, name='output')(X)     # output layer\n",
        "    \n",
        "    model = Model(I, X, name='Example_1')               # return a neural model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5i7QH7YlqBr"
      },
      "source": [
        "if 'model' in globals(): del model             # to reset model\n",
        "model = fully_connected_model(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD-raP1OlqBu"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_aTjBDnlqB2"
      },
      "source": [
        "## Training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQSF39G9lqB2"
      },
      "source": [
        "# define optimizer, loss function and metrics\n",
        "alpha = 1.\n",
        "opt = optimizers.Adam(learning_rate=alpha, decay=1e-3)\n",
        "#opt = optimizers.SGD(learning_rate=alpha, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "model.compile(optimizer=opt, loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72eJF8SalqB7"
      },
      "source": [
        "# fitting\n",
        "tic = time()\n",
        "history = model.fit(x_train, y_train, batch_size=16, epochs=15, validation_data=[x_val, y_val], verbose=1)\n",
        "toc = time()\n",
        "print('total training time:', toc-tic, 'seconds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f083RcAHlqB_"
      },
      "source": [
        "history_dict = history.history\n",
        "keys = list(history_dict.keys())\n",
        "print(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIozvm6YlqCD"
      },
      "source": [
        "loss = history.history[keys[0]]\n",
        "met = history.history[keys[1]]\n",
        "val_loss = history.history[keys[2]]\n",
        "val_met = history.history[keys[3]]\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "# figure\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, met, 'r', label='Training metric')\n",
        "plt.plot(epochs, val_met, 'g', label='Validation metric')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel(keys[1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBvKKeyXlqCG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyfqB9F4lqCJ"
      },
      "source": [
        "# save model\n",
        "save_model(model, 'Example_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev92jIGJlqCM"
      },
      "source": [
        "test = model.evaluate(x_test, y_test)\n",
        "print('test MSE:', test[0])\n",
        "print('test MAE:', test[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7puYSs-lqCO"
      },
      "source": [
        "If you want to load your saved model, just uncomment the following line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2a3_zA-lqCP"
      },
      "source": [
        "# load a saved model\n",
        "#model = load_model('Example_1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwn-BXFolqCR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCw6saAQlqCT"
      },
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxKSMXiClqCU"
      },
      "source": [
        "y_hat = model.predict(x_test)\n",
        "print(y_hat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVZPgJF4lqCW"
      },
      "source": [
        "# plot x_test, y_test and predicted data\n",
        "plt.figure()\n",
        "plt.plot(x_test, y_test, 'bo', label='observed data')\n",
        "plt.plot(x_test, y_hat, 'ro', label='predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkVqaKt0lqCY"
      },
      "source": [
        "xidx = np.argsort(x_test.ravel())\n",
        "x_test_ord = x_test[xidx]\n",
        "y_test_ord = y_test[xidx]\n",
        "y_hatt_ord = y_hat[xidx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IApJSCdXlqCa"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_test_ord, y_test_ord, 'b-', label='observed data')\n",
        "plt.plot(x_test_ord, y_hatt_ord, 'r-', label='predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-H8-fBTplqCd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R18XRBNWlqCf"
      },
      "source": [
        "## Define a Second Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gInJmkGlqCf"
      },
      "source": [
        "def fully_connected_model_2(input_shape):\n",
        "    I = Input(input_shape, name='input')                 # input layer\n",
        "    ### ADD SOME LAYERS HERE ###\n",
        "        \n",
        "    model = Model(I, X, name='Example_2')                # return model\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjfYd1gSlqCi"
      },
      "source": [
        "if 'model2' in globals(): del model2\n",
        "model2 = None\n",
        "model2 = fully_connected_model_2(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGLl80FllqCl"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW_-sm20lqCm"
      },
      "source": [
        "## Training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDRij5ahlqCn"
      },
      "source": [
        "# define optimizer, loss function and metrics\n",
        "alpha = 1e-3\n",
        "opt = optimizers.Adam(learning_rate=alpha, decay=1e-3)\n",
        "\n",
        "model2.compile(optimizer=opt, loss='mse', metrics=['mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCfYroDflqCp"
      },
      "source": [
        "# fitting\n",
        "tic = time()\n",
        "history = model2.fit(x_train, y_train, batch_size=16, epochs=200, validation_data=[x_val, y_val], verbose=1)\n",
        "toc = time()\n",
        "print('total training time:', toc-tic, 'seconds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5g24qbhlqCr"
      },
      "source": [
        "history_dict = history.history\n",
        "keys = list(history_dict.keys())\n",
        "print(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Hxy5ailqCt"
      },
      "source": [
        "#plot learning curves\n",
        "loss = history.history[keys[0]]\n",
        "met = history.history[keys[1]]\n",
        "val_loss = history.history[keys[2]]\n",
        "val_met = history.history[keys[3]]\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "# figure\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, met, 'r', label='Training metric')\n",
        "plt.plot(epochs, val_met, 'g', label='Validation metric')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel(keys[1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUqHHi--lqCu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC6UD2P-lqCx"
      },
      "source": [
        "# save model\n",
        "save_model(model2, 'Example_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeFIdaP-lqCz"
      },
      "source": [
        "# evaluate performance on test data\n",
        "test = model2.evaluate(x_test, y_test)\n",
        "print('test MSE:', test[0])\n",
        "print('test MAE:', test[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTDAwShlqC1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE5oWei6lqC2"
      },
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOCMLZ5_lqC3"
      },
      "source": [
        "y_hat = model2.predict(x_test)\n",
        "print(y_hat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_xz3cC1lqC5"
      },
      "source": [
        "# plot test and predicted data\n",
        "plt.figure()\n",
        "plt.plot(x_test, y_test, 'bo', label='observed data')\n",
        "plt.plot(x_test, y_hat, 'ro', label='predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zhHpKJBlqC-"
      },
      "source": [
        "xidx = np.argsort(x_test.ravel())\n",
        "x_test_ord = x_test[xidx]\n",
        "y_test_ord = y_test[xidx]\n",
        "y_hatt_ord = y_hat[xidx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WN89mv5ulqDC"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_test_ord, y_test_ord, 'b-', label='observed data')\n",
        "plt.plot(x_test_ord, y_hatt_ord, 'r-', label='predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9or8TAlqDE"
      },
      "source": [
        "x_new = np.linspace(2.0, 3.0, 21).reshape(-1,1)\n",
        "print(x_new.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3p3WqrflqDG"
      },
      "source": [
        "y_new = f(x_new, sigma=0.)\n",
        "print(y_new.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EHwSy4vlqDJ"
      },
      "source": [
        "y_new_hat = model2.predict(x_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Y_zevSlqDK"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_test_ord, y_test_ord, 'b-', label='observed data')\n",
        "plt.plot(x_test_ord, y_hatt_ord, 'r-', label='predicted data')\n",
        "plt.plot(x_new, y_new, 'k-', label='observed new')\n",
        "plt.plot(x_new, y_new_hat, 'g-', label='predicted new')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM2BCECulqDM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD5TVqQXlqDO"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5tIOiVblqDO"
      },
      "source": [
        "Consider now synthetic data generated by function $g$.\n",
        "\n",
        "1. Explore the new data. Split in train, validation and test.\n",
        "2. Define a neural network model, with various dense layers (choose the number of neuron as your election). \n",
        "3. Train your model and evaluate your results with the test data (plot a graph comparing the y_test and the predicted estimations by the model). \n",
        "\n",
        "If possible, explore differente activation functions, such as 'sigmoid', 'tanh', 'leaky-relu'.\n",
        "\n",
        "If possible, explore different optimizers (e.g. SGD, RMSProp, Adagrad, Adamax), different learning rates, a different batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj9uv7g_lqDO"
      },
      "source": [
        "train_size = 1000\n",
        "noise = 0.15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k1x5vNLlqDQ"
      },
      "source": [
        "# generate new data\n",
        "x = np.linspace(0., 10., train_size).reshape(-1,1)\n",
        "print(x.shape)\n",
        "\n",
        "y = g(x, sigma=noise)\n",
        "y_true = g(x, sigma=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjgZ2LNslqDR"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x, y_true, label='true')\n",
        "plt.plot(x, y, 'k+', label='data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyZJVDCslqDU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf0k-AjMlqDV"
      },
      "source": [
        "## Split data in Train / Validaton / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27M-ywVGlqDW"
      },
      "source": [
        "n = x.shape[0]\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu60nYCUlqDY"
      },
      "source": [
        "# shuffle index\n",
        "seed = np.random.seed(12112020)\n",
        "idx = np.random.permutation(np.arange(0, n))\n",
        "print(idx[:20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vebPc8cJlqDa"
      },
      "source": [
        "### DEFINE YOUR PERCENTAGES FOR TRAIn / VALIDATION / TEST ###\n",
        "p_train = \n",
        "p_val   = \n",
        "\n",
        "### DEFINE YOUR INDEX WHERE THE DATA WILL BE CUT ###\n",
        "a =\n",
        "b =\n",
        "\n",
        "### SPLIT YOUR DATA IN TRINING, VALIDATION AND TEST HERE ###\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uuI3_1ZlqDd"
      },
      "source": [
        "# print shape of data (just for verification)\n",
        "print(x_train.shape, x_val.shape, x_test.shape)\n",
        "print(y_train.shape, y_val.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZTQDZMTlqDe"
      },
      "source": [
        "# plot x_train and y_train data\n",
        "plt.figure()\n",
        "plt.plot(x_train, y_true[idx[:a]], 'b.', label='true')\n",
        "plt.plot(x_train, y_train, 'k+', label='data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvEZe7mplqDf"
      },
      "source": [
        "# define input_shape\n",
        "input_shape = x_train.shape[1:]\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpzJzJZtlqDg"
      },
      "source": [
        "### DEFINE YOUR MODEL HERE ###\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GbQmu7MlqDi"
      },
      "source": [
        "if 'model_ex2' in globals(): del model_ex2\n",
        "model_ex2 = None\n",
        "\n",
        "### CREATE THE NEW INSTANCE OF YOUR MODEL HERE ###\n",
        "model_ex2 = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6QJcKdllqDj"
      },
      "source": [
        "model_ex2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XPZHsKFlqDk"
      },
      "source": [
        "## Training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5LXrgxvlqDk"
      },
      "source": [
        "# define optimizer, loss function and metrics\n",
        "\n",
        "### DEFINE ALPHA AND OPTIMIZER HERE ###\n",
        "\n",
        "### COMPILE YOUR MODEL HERE ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkchSHeylqDl"
      },
      "source": [
        "# fitting\n",
        "tic = time()\n",
        "### FIT YOUR MODEL HERE ###\n",
        "\n",
        "toc = time()\n",
        "print('total training time:', toc-tic, 'seconds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbAU-JWMlqDm"
      },
      "source": [
        "history_dict = history.history\n",
        "keys = list(history_dict.keys())\n",
        "print(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2jD_JKRlqDo"
      },
      "source": [
        "# plot learning curves\n",
        "loss = history.history[keys[0]]\n",
        "met = history.history[keys[1]]\n",
        "val_loss = history.history[keys[2]]\n",
        "val_met = history.history[keys[3]]\n",
        "\n",
        "epochs = range(1, len(loss)+1)\n",
        "\n",
        "# figure\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, met, 'r', label='Training metric')\n",
        "plt.plot(epochs, val_met, 'g', label='Validation metric')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel(keys[1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev1-axcPlqDp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMWHrbNjlqDr"
      },
      "source": [
        "# save model\n",
        "save_model(model_ex2, 'Exercise_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihqkJJk9lqDs"
      },
      "source": [
        "# evaluate performance on test data\n",
        "test = model_ex2.evaluate(x_test, y_test)\n",
        "print('test MSE:', test[0])\n",
        "print('test MAE:', test[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8k7iE6ITlqDt"
      },
      "source": [
        "## Predict on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow3I8MTGlqDu"
      },
      "source": [
        "y_hat = model_ex2.predict(x_test)\n",
        "print(y_hat.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLQZ8Ls2lqDv"
      },
      "source": [
        "# plot test and predicted data\n",
        "plt.figure()\n",
        "plt.plot(x_test, y_test, 'bo', label='observed data')\n",
        "plt.plot(x_test, y_hat, 'ro', label='predicted data')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg4l3wdnlqDw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byxOVgJblqDx"
      },
      "source": [
        "## Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8C8_OHxlqDy"
      },
      "source": [
        "Train a fully connected neural network to estimate the number of infected people by Covid-19.\n",
        "Use the data provided for the Project 1 by professor Leticia.\n",
        "\n",
        "1. Explore the new data. Split in train, validation and test.\n",
        "2. Define a neural network model, with various dense layers (choose the number of neuron as your election). \n",
        "3. Train your model and evaluate your results with the test data (plot a graph comparing the y_test and the predicted estimations by the model).\n",
        "4. Try to make predictions in the following days after the last available data (not too far).\n",
        "\n",
        "Observation: I recommend not to aggregate the data by week, because this will severely reduce the number of samples. Use data by day. If you want to reduce the noise in the data, instead of the raw numbers you can replace them by an moving average of 7 days."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bbtPnslqDy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}